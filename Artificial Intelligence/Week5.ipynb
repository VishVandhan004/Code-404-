{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44627e85-3acc-4bea-9ec6-7eee976df2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\talak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\talak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\talak\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e212aed-ca30-4d82-9239-e4720e4a76ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have a rendezvous with Death, At some disputed barricade.When Spring comes back with rustling shade, And apple blossoms fill coming the air.', '“I have a rendezvous with Death” When Springbrings back blue days came and fair.', 'And I have learned too to laugh with only my teeth and shake hands without my heart.', 'I have also learned to say, ’Goodbye’,when I mean ‘Good-riddance’:to say ‘Glad to meet you’, without being glad; and to say ‘It’s been nice talking to you’, after being bored']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"I have a rendezvous with Death, At some disputed barricade.When Spring comes back with rustling shade, And apple blossoms fill coming the air. “I have a rendezvous with Death” When Springbrings back blue days came and fair. And I have learned too to laugh with only my teeth and shake hands without my heart. I have also learned to say, ’Goodbye’,when I mean ‘Good-riddance’:to say ‘Glad to meet you’, without being glad; and to say ‘It’s been nice talking to you’, after being bored\"\n",
    "tokenized_text = sent_tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec03e71-ccad-4a81-9408-833dd14cc90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'a', 'rendezvous', 'with', 'Death', ',', 'At', 'some', 'disputed', 'barricade.When', 'Spring', 'comes', 'back', 'with', 'rustling', 'shade', ',', 'And', 'apple', 'blossoms', 'fill', 'coming', 'the', 'air', '.', '“', 'I', 'have', 'a', 'rendezvous', 'with', 'Death', '”', 'When', 'Springbrings', 'back', 'blue', 'days', 'came', 'and', 'fair', '.', 'And', 'I', 'have', 'learned', 'too', 'to', 'laugh', 'with', 'only', 'my', 'teeth', 'and', 'shake', 'hands', 'without', 'my', 'heart', '.', 'I', 'have', 'also', 'learned', 'to', 'say', ',', '’', 'Goodbye', '’', ',', 'when', 'I', 'mean', '‘', 'Good-riddance', '’', ':', 'to', 'say', '‘', 'Glad', 'to', 'meet', 'you', '’', ',', 'without', 'being', 'glad', ';', 'and', 'to', 'say', '‘', 'It', '’', 's', 'been', 'nice', 'talking', 'to', 'you', '’', ',', 'after', 'being', 'bored']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_word = word_tokenize(text)\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8997b16a-2846-4dbb-acc5-62cd15b66761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 66 samples and 109 outcomes>\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ece8a0b-b402-4e7c-84b8-7644d4a3875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 6), ('to', 6)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "274ef085-f7a3-4359-8c26-f860db8f551c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'so', 'can', 'out', 'once', 'i', 'will', \"should've\", 'up', 'should', \"shouldn't\", 'by', 'doing', 'whom', \"shan't\", 'shouldn', 'through', \"haven't\", 'against', 'your', 'to', 'again', 'its', 'until', 'off', 'just', 'couldn', 'of', 'a', 'were', 'over', 'further', 'about', 'she', \"needn't\", 'yourselves', 'he', 'have', 'has', 'too', 'as', 'wasn', 'being', 'when', \"you'll\", 'isn', 'was', 'hers', 'needn', 'each', 'these', 't', 'itself', 'how', 's', 'yours', 're', \"hadn't\", 'yourself', \"you're\", 'below', 'doesn', \"she's\", 'an', 'm', 'here', 'more', 'am', 'which', 'does', 'but', 'shan', 'it', 'few', 'been', 'now', 'mustn', 'her', 'mightn', \"you'd\", \"mustn't\", 'only', 'than', 'theirs', 've', \"mightn't\", 'those', 'or', 'then', 'hadn', \"aren't\", 'weren', 'this', \"hasn't\", 'wouldn', 'don', 'that', 'be', 'both', 'into', 'ain', 'our', 'between', 'from', 'is', \"weren't\", 'ourselves', 'there', 'under', 'no', 'who', 'did', 'any', 'myself', 'such', 'his', 'them', 'during', 'some', 'their', \"it's\", \"doesn't\", \"don't\", 'o', \"didn't\", \"wouldn't\", 'most', 'haven', 'the', 'what', 'do', 'y', 'on', \"you've\", \"won't\", 'aren', \"couldn't\", 'while', 'hasn', 'having', 'my', 'ma', 'll', 'above', 'very', 'are', 'if', 'won', \"that'll\", 'where', 'all', 'ours', 'they', 'after', 'own', 'didn', 'we', 'themselves', 'in', 'not', 'with', 'other', \"isn't\", 'because', 'for', 'herself', 'at', 'me', 'same', 'down', 'before', \"wasn't\", 'nor', 'and', 'him', 'd', 'why', 'you', 'had', 'himself'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77b8ba6-34ba-4367-b132-b9de8d76ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence:  ['I', 'have', 'a', 'rendezvous', 'with', 'Death', ',', 'At', 'some', 'disputed', 'barricade.When', 'Spring', 'comes', 'back', 'with', 'rustling', 'shade', ',', 'And', 'apple', 'blossoms', 'fill', 'coming', 'the', 'air', '.', '“', 'I', 'have', 'a', 'rendezvous', 'with', 'Death', '”', 'When', 'Springbrings', 'back', 'blue', 'days', 'came', 'and', 'fair', '.', 'And', 'I', 'have', 'learned', 'too', 'to', 'laugh', 'with', 'only', 'my', 'teeth', 'and', 'shake', 'hands', 'without', 'my', 'heart', '.', 'I', 'have', 'also', 'learned', 'to', 'say', ',', '’', 'Goodbye', '’', ',', 'when', 'I', 'mean', '‘', 'Good-riddance', '’', ':', 'to', 'say', '‘', 'Glad', 'to', 'meet', 'you', '’', ',', 'without', 'being', 'glad', ';', 'and', 'to', 'say', '‘', 'It', '’', 's', 'been', 'nice', 'talking', 'to', 'you', '’', ',', 'after', 'being', 'bored']\n",
      "Filtered Sentence:  ['I', 'rendezvous', 'Death', ',', 'At', 'disputed', 'barricade.When', 'Spring', 'comes', 'back', 'rustling', 'shade', ',', 'And', 'apple', 'blossoms', 'fill', 'coming', 'air', '.', '“', 'I', 'rendezvous', 'Death', '”', 'When', 'Springbrings', 'back', 'blue', 'days', 'came', 'fair', '.', 'And', 'I', 'learned', 'laugh', 'teeth', 'shake', 'hands', 'without', 'heart', '.', 'I', 'also', 'learned', 'say', ',', '’', 'Goodbye', '’', ',', 'I', 'mean', '‘', 'Good-riddance', '’', ':', 'say', '‘', 'Glad', 'meet', '’', ',', 'without', 'glad', ';', 'say', '‘', 'It', '’', 'nice', 'talking', '’', ',', 'bored']\n"
     ]
    }
   ],
   "source": [
    "filtered_sent = []\n",
    "for w in tokenized_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)\n",
    "print(\"Tokenized Sentence: \",tokenized_word)\n",
    "print(\"Filtered Sentence: \",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26b85cf7-fd0f-43d4-a8fe-fb416ff8a74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence: ['I', 'rendezvous', 'Death', ',', 'At', 'disputed', 'barricade.When', 'Spring', 'comes', 'back', 'rustling', 'shade', ',', 'And', 'apple', 'blossoms', 'fill', 'coming', 'air', '.', '“', 'I', 'rendezvous', 'Death', '”', 'When', 'Springbrings', 'back', 'blue', 'days', 'came', 'fair', '.', 'And', 'I', 'learned', 'laugh', 'teeth', 'shake', 'hands', 'without', 'heart', '.', 'I', 'also', 'learned', 'say', ',', '’', 'Goodbye', '’', ',', 'I', 'mean', '‘', 'Good-riddance', '’', ':', 'say', '‘', 'Glad', 'meet', '’', ',', 'without', 'glad', ';', 'say', '‘', 'It', '’', 'nice', 'talking', '’', ',', 'bored']\n",
      "\n",
      "\n",
      "Stemmed Sentence: ['i', 'rendezv', 'death', ',', 'at', 'disput', 'barricade.when', 'spring', 'come', 'back', 'rustl', 'shade', ',', 'and', 'appl', 'blossom', 'fill', 'come', 'air', '.', '“', 'i', 'rendezv', 'death', '”', 'when', 'springbr', 'back', 'blue', 'day', 'came', 'fair', '.', 'and', 'i', 'learn', 'laugh', 'teeth', 'shake', 'hand', 'without', 'heart', '.', 'i', 'also', 'learn', 'say', ',', '’', 'goodby', '’', ',', 'i', 'mean', '‘', 'good-ridd', '’', ':', 'say', '‘', 'glad', 'meet', '’', ',', 'without', 'glad', ';', 'say', '‘', 'it', '’', 'nice', 'talk', '’', ',', 'bore']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "ps=PorterStemmer()\n",
    "stemmed_words=[]\n",
    "for w in filtered_sent:\n",
    "        stemmed_words.append(ps.stem(w))\n",
    "print(\"Filtered Sentence:\",filtered_sent)\n",
    "print(\"\\n\")\n",
    "print(\"Stemmed Sentence:\",stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03b4bf54-d6bc-4ee8-bc10-d932791a2544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-->I\n",
      "rendezvous-->rendezvous\n",
      "Death-->Death\n",
      ",-->,\n",
      "At-->At\n",
      "disputed-->disputed\n",
      "barricade.When-->barricade.When\n",
      "Spring-->Spring\n",
      "comes-->come\n",
      "back-->back\n",
      "rustling-->rustling\n",
      "shade-->shade\n",
      ",-->,\n",
      "And-->And\n",
      "apple-->apple\n",
      "blossoms-->blossom\n",
      "fill-->fill\n",
      "coming-->coming\n",
      "air-->air\n",
      ".-->.\n",
      "“-->“\n",
      "I-->I\n",
      "rendezvous-->rendezvous\n",
      "Death-->Death\n",
      "”-->”\n",
      "When-->When\n",
      "Springbrings-->Springbrings\n",
      "back-->back\n",
      "blue-->blue\n",
      "days-->day\n",
      "came-->came\n",
      "fair-->fair\n",
      ".-->.\n",
      "And-->And\n",
      "I-->I\n",
      "learned-->learned\n",
      "laugh-->laugh\n",
      "teeth-->teeth\n",
      "shake-->shake\n",
      "hands-->hand\n",
      "without-->without\n",
      "heart-->heart\n",
      ".-->.\n",
      "I-->I\n",
      "also-->also\n",
      "learned-->learned\n",
      "say-->say\n",
      ",-->,\n",
      "’-->’\n",
      "Goodbye-->Goodbye\n",
      "’-->’\n",
      ",-->,\n",
      "I-->I\n",
      "mean-->mean\n",
      "‘-->‘\n",
      "Good-riddance-->Good-riddance\n",
      "’-->’\n",
      ":-->:\n",
      "say-->say\n",
      "‘-->‘\n",
      "Glad-->Glad\n",
      "meet-->meet\n",
      "’-->’\n",
      ",-->,\n",
      "without-->without\n",
      "glad-->glad\n",
      ";-->;\n",
      "say-->say\n",
      "‘-->‘\n",
      "It-->It\n",
      "’-->’\n",
      "nice-->nice\n",
      "talking-->talking\n",
      "’-->’\n",
      ",-->,\n",
      "bored-->bored\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "words = []\n",
    "for words in filtered_sent:\n",
    "    print(words +\"-->\"+ wnl.lemmatize(words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a046305c-e391-4210-bb0a-d6fe8e5ce6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\talak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29357c61-cec1-4ac0-8b79-2828ab33d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('rendezvous', 'JJ'), ('with', 'IN'), ('Death', 'NNP'), (',', ','), ('At', 'IN'), ('some', 'DT'), ('disputed', 'VBN'), ('barricade.When', 'NN'), ('Spring', 'NNP'), ('come', 'VBZ'), ('back', 'RB'), ('with', 'IN'), ('rustling', 'VBG'), ('shade', 'NN'), (',', ','), ('And', 'CC'), ('apple', 'NN'), ('blossom', 'NN'), ('fill', 'NN'), ('coming', 'VBG'), ('the', 'DT'), ('air', 'NN'), ('.', '.'), ('“', 'NN'), ('I', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('rendezvous', 'JJ'), ('with', 'IN'), ('Death', 'NNP'), ('”', 'NN'), ('When', 'WRB'), ('Springbrings', 'NNP'), ('back', 'RB'), ('blue', 'JJ'), ('day', 'NN'), ('came', 'VBD'), ('and', 'CC'), ('fair', 'JJ'), ('.', '.'), ('And', 'CC'), ('I', 'PRP'), ('have', 'VBP'), ('learned', 'VBN'), ('too', 'RB'), ('to', 'TO'), ('laugh', 'VB'), ('with', 'IN'), ('only', 'JJ'), ('my', 'PRP$'), ('teeth', 'NNS'), ('and', 'CC'), ('shake', 'VB'), ('hand', 'NN'), ('without', 'IN'), ('my', 'PRP$'), ('heart', 'NN'), ('.', '.'), ('I', 'PRP'), ('have', 'VBP'), ('also', 'RB'), ('learned', 'VBN'), ('to', 'TO'), ('say', 'VB'), (',', ','), ('’', 'FW'), ('Goodbye', 'NNP'), ('’', 'NNP'), (',', ','), ('when', 'WRB'), ('I', 'PRP'), ('mean', 'VBP'), ('‘', 'JJ'), ('Good-riddance', 'NNP'), ('’', 'NN'), (':', ':'), ('to', 'TO'), ('say', 'VB'), ('‘', 'NNP'), ('Glad', 'NNP'), ('to', 'TO'), ('meet', 'VB'), ('you', 'PRP'), ('’', 'VBP'), (',', ','), ('without', 'IN'), ('being', 'VBG'), ('glad', 'NN'), (';', ':'), ('and', 'CC'), ('to', 'TO'), ('say', 'VB'), ('‘', 'IN'), ('It', 'PRP'), ('’', 'VBZ'), ('s', 'RB'), ('been', 'VBN'), ('nice', 'JJ'), ('talking', 'VBG'), ('to', 'TO'), ('you', 'PRP'), ('’', 'VB'), (',', ','), ('after', 'IN'), ('being', 'VBG'), ('bored', 'VBD')]\n"
     ]
    }
   ],
   "source": [
    "wrl = WordNetLemmatizer()\n",
    "lemmatized_words = [wrl.lemmatize(word) for word in nltk.word_tokenize(text)]\n",
    "# Perform part-of-speech tagging\n",
    "final = nltk.pos_tag(lemmatized_words)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18501813-dae2-480d-8494-efd20fa22995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\talak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping help\\tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1b1656c-9285-428c-a9de-6efa22613c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('JJ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
